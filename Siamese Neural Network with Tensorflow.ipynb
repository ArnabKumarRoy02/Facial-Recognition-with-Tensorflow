{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74a0060",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Installing the dependencies\n",
    "%pip install tensorflow-gpu tensorflow==2.9 opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25d3f269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the standard libraries\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59f16749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Tensorflow dependencies - Functional API\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858a12b9",
   "metadata": {},
   "source": [
    "## Setup GPU Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "217ace6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid OOM (Out of Memory) errors by setting GPU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca046a9",
   "metadata": {},
   "source": [
    "## Create folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c853d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup paths\n",
    "POS_PATH = os.path.join('data', 'positive')\n",
    "NEG_PATH = os.path.join('data', 'negative')\n",
    "ANC_PATH = os.path.join('data', 'anchor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f607ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make directories\n",
    "os.makedirs(POS_PATH)\n",
    "os.makedirs(NEG_PATH)\n",
    "os.makedirs(ANC_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b940f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.removedirs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b938a57",
   "metadata": {},
   "source": [
    "# Collect Positive and Anchors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd139795",
   "metadata": {},
   "source": [
    "## Untar Labelled Faces in the Wild Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78e601b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncompress Tar GZ labelled Faces in the wild dataset\n",
    "!tar -xf lfw.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fa62f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move LFW Images to the following repository data/negative\n",
    "for directory in os.listdir('lfw'):\n",
    "    for file in os.listdir(os.path.join('lfw', directory)):\n",
    "        EX_PATH = os.path.join('lfw', directory, file)\n",
    "        NEW_PATH = os.path.join(NEG_PATH, file)\n",
    "        os.replace(EX_PATH, NEW_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d7ddcf",
   "metadata": {},
   "source": [
    "## Collect Positive and Anchor Classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc9b865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the uuid library to generate unique image names\n",
    "import uuid\n",
    "# uuid - universally unique identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa644f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'{}.jpg'.format(uuid.uuid1())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e784e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a connection to the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Cut down the frame to 250x250 px\n",
    "    frame = frame[120:120+250, 200:200+250, :]\n",
    "    \n",
    "    # Collect anchors\n",
    "    if cv2.waitKey(1) & 0XFF == ord('a'):\n",
    "        # Create the unique file path\n",
    "        imgname = os.path.join(ANC_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "        # Write out anchor image\n",
    "        cv2.imwrite(imgname, frame)\n",
    "    \n",
    "    # Collect positives\n",
    "    if cv2.waitKey(1) & 0XFF == ord('p'):\n",
    "        # Create the unique file path\n",
    "        imgname = os.path.join(POS_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "        # Write out positive image\n",
    "        cv2.imwrite(imgname, frame)\n",
    "    \n",
    "    # Show image back to screen\n",
    "    cv2.imshow('Image Collection', frame)\n",
    "    \n",
    "    # Breaking gracefully\n",
    "    if cv2.waitKey(1) & 0XFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "# Release the webcam\n",
    "cap.release()\n",
    "# Close the image show frame\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f9430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a5aeec",
   "metadata": {},
   "source": [
    "# Load and Preprocess images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c158e9",
   "metadata": {},
   "source": [
    "## Get Image Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c208edea",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = tf.data.Dataset.list_files(ANC_PATH+'\\*.jpg').take(300)\n",
    "positive = tf.data.Dataset.list_files(POS_PATH+'\\*.jpg').take(300)\n",
    "negative = tf.data.Dataset.list_files(NEG_PATH+'\\*.jpg').take(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57cfc5bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'anchor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dir_test \u001b[38;5;241m=\u001b[39m \u001b[43manchor\u001b[49m\u001b[38;5;241m.\u001b[39mas_numpy_iterator()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'anchor' is not defined"
     ]
    }
   ],
   "source": [
    "dir_test = anchor.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bff97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_test.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88c2060",
   "metadata": {},
   "source": [
    "## Preprocessing - Scale and Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18e71844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path):\n",
    "    \n",
    "    # Read in image from file path\n",
    "    byte_img = tf.io.read_file(file_path)\n",
    "    # Load in the image\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    \n",
    "    # Preprocessing steps - resizing the image to 100x100x3\n",
    "    img = tf.image.resize(img, (100, 100))\n",
    "    # Scale image between 0 and 1\n",
    "    img = img / 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac92c6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = preprocess('data\\\\anchor\\\\55c66f8c-1a77-11ed-9447-3ca067c97eb7.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1d7044",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cc5cbd",
   "metadata": {},
   "source": [
    "## Create Labelled Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9fa3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (anchor, positive) => 1,1,1,1,1\n",
    "# (anchor, negative) => 0,0,0,0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f218a5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = tf.data.Dataset.zip((anchor, positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
    "negatives = tf.data.Dataset.zip((anchor, negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
    "data = positives.concatenate(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b16a3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e093fe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = samples.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757f9762",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6668e6b4",
   "metadata": {},
   "source": [
    "## Build Train and Test Partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5fdffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_twin(input_img, validation_img, label):\n",
    "    return(preprocess(input_img), preprocess(validation_img), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bfc58237",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = preprocess_twin(*examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81243be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dee6be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "132da95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataloader pipeline\n",
    "data = data.map(preprocess_twin)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c4e33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(len(data)*.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c99b94ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training partition\n",
    "train_data = data.take(round(len(data)*.7))\n",
    "train_data = train_data.batch(16)\n",
    "train_data = train_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6b953b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = train_data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cffec24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = train_samples.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223aa55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(len(data)*.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "886daddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing partition\n",
    "test_data = data.skip(round(len(data)*.7))\n",
    "test_data = test_data.take(round(len(data)*.3))\n",
    "test_data = test_data.batch(16)\n",
    "test_data = test_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f1cc85",
   "metadata": {},
   "source": [
    "# Model Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6fe283",
   "metadata": {},
   "source": [
    "## Build Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "462443b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(100,100,3), name='input_image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b5bd5720",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = Conv2D(64, (10,10), activation='relu')(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da78e20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a288ee9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = MaxPooling2D(64, (2,2), padding='same')(c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c2e30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "73e6b8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = Conv2D(128, (7,7), activation='relu')(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8004df69",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "38de19d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = MaxPooling2D(64, (2,2), padding='same')(c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8cbd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "68220019",
   "metadata": {},
   "outputs": [],
   "source": [
    "c3 = Conv2D(128, (4,4), activation='relu')(m2)\n",
    "m3 = MaxPooling2D(64, (2,2), padding='same')(c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffa11fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "c3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c14cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a1d8ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "c4 = Conv2D(256, (4,4), activation='relu')(m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e48bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "953f4394",
   "metadata": {},
   "outputs": [],
   "source": [
    "c4 = Conv2D(256, (4,4), activation='relu')(m3)\n",
    "f1 = Flatten()(c4)\n",
    "d1 = Dense(4096, activation='sigmoid')(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aa5a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af09a8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57755640",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b958797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = Model(inputs=[inp], outputs=[d1], name='embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae961c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "06cb2273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding():\n",
    "    inp = Input(shape=(100,100,3), name='input_image')\n",
    "    \n",
    "    # First block\n",
    "    c1 = Conv2D(64, (10,10), activation='relu')(inp)\n",
    "    m1 = MaxPooling2D(64, (2,2), padding='same')(c1)\n",
    "    \n",
    "    # Second block\n",
    "    c2 = Conv2D(128, (7,7), activation='relu')(m1)\n",
    "    m2 = MaxPooling2D(64, (2,2), padding='same')(c2)\n",
    "    \n",
    "    # Third block\n",
    "    c3 = Conv2D(128, (4,4), activation='relu')(m2)\n",
    "    m3 = MaxPooling2D(64, (2,2), padding='same')(c3)\n",
    "    \n",
    "    # Final layer\n",
    "    c4 = Conv2D(256, (4,4), activation='relu')(m3)\n",
    "    f1 = Flatten()(c4)\n",
    "    d1 = Dense(4096, activation='sigmoid')(f1)\n",
    "    \n",
    "    return Model(inputs=[inp], outputs=[d1], name='embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "996bbf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = make_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1a7e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746c006a",
   "metadata": {},
   "source": [
    "## Build Distance Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "27bb1c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Siamese L1 Distance class\n",
    "class L1Dist(Layer):\n",
    "    \n",
    "    # Init method - inheritance\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "                \n",
    "    # Similarity calculation        \n",
    "    def call(self, input_embedding, validation_embedding):\n",
    "        return tf.math.abs(input_embedding - validation_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cc019ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = L1Dist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904e5968",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ca9e4c",
   "metadata": {},
   "source": [
    "## Make Siamese Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "83b2e47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = Input(name='input_img', shape=(100,100,3))\n",
    "validation_image = Input(name='validation_img', shape=(100,100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3a98f526",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_embedding = embedding(input_image)\n",
    "val_embedding = embedding(validation_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "859f15e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_layer = L1Dist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fa6dee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = siamese_layer(inp_embedding, val_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "559eeb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Dense(1, activation='sigmoid')(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69da2ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fd78b61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_network = Model(inputs=[input_image, validation_image], outputs=classifier, name='SiameseNetwork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5442479a",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "18099ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_siamese_model():\n",
    "    \n",
    "    # Anchor image input in the network\n",
    "    input_image = Input(name='input_img', shape=(100,100,3))\n",
    "    \n",
    "    # Validation image input in the network\n",
    "    validation_image = Input(name='validation_img', shape=(100,100,3))\n",
    "    \n",
    "    # Combine siamese distance components\n",
    "    siamese_layer = L1Dist()\n",
    "    siamese_layer._name = 'distance'\n",
    "    distances = siamese_layer(embedding(input_image), embedding(validation_image))\n",
    "       \n",
    "    # Classification layer\n",
    "    classifier = Dense(1, activation='sigmoid')(distances)\n",
    "    \n",
    "    return Model(inputs=[input_image, validation_image], outputs=classifier, name='SiameseNetwork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d88f3a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model = make_siamese_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e48360",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fba8fcb",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0118ef",
   "metadata": {},
   "source": [
    "## 1. Setup Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a12742e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cross_loss = tf.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "67f9cbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c62f1b",
   "metadata": {},
   "source": [
    "## 2. Establish Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "adff28c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(opt=opt, siamese_model=siamese_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945b3cb3",
   "metadata": {},
   "source": [
    "## 3. Build Train Step Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2770ef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = train_data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "28877271",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_1 = test_batch.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "04ebeaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = batch_1[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe09b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f347834d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = batch_1[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e24d680",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "90fde970",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(batch):\n",
    "    \n",
    "    # Record all of the operations\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Get anchor and positive/negative image\n",
    "        X = batch[:2]\n",
    "        # Get label\n",
    "        y = batch[2]\n",
    "        \n",
    "        # Forward pass\n",
    "        yhat = siamese_model(X, training=True)\n",
    "        # Calculate loss\n",
    "        loss = binary_cross_loss(y, yhat)\n",
    "    print(loss)\n",
    "        \n",
    "    # Calculate gradients\n",
    "    grad = tape.gradient(loss, siamese_model.trainable_variables)\n",
    "    \n",
    "    # Calculate updated weights and apply to siamese model\n",
    "    opt.apply_gradients(zip(grad, siamese_model.trainable_variables))\n",
    "    \n",
    "    # Return loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd98902",
   "metadata": {},
   "source": [
    "## 4. Build Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2a5559f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, EPOCHS):\n",
    "    # Loop through epochs\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        print('\\n Epoch {}/{}'.format(epoch, EPOCHS))\n",
    "        progbar = tf.keras.utils.Progbar(len(data))\n",
    "        \n",
    "        # Loop through each batch\n",
    "        for idx, batch in enumerate(data):\n",
    "            # Run train step\n",
    "            train_step(batch)\n",
    "            progbar.update(idx+1)\n",
    "            \n",
    "        # Save checkpoints\n",
    "        if epoch % 10 == 0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6b4630",
   "metadata": {},
   "source": [
    "## 5. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9057218a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340dc732",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train(train_data, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde44edb",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4993bba7",
   "metadata": {},
   "source": [
    "## 1. Import Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1d141fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import metric calculations\n",
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1218564",
   "metadata": {},
   "source": [
    "## 2. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "994f89ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of test data\n",
    "test_input, test_val, y_true = test_data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4496a0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_var = test_data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f395d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_hat = siamese_model.predict([test_input, test_val])\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67f188c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post processing the results\n",
    "[1 if prediction > 0.5 else 0 for prediction in y_hat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1c688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c40449",
   "metadata": {},
   "source": [
    "## 3. Calculate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4463cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a metric object\n",
    "m = Recall()\n",
    "\n",
    "# Calculating the recall value\n",
    "m.update_state(y_true, y_hat)\n",
    "\n",
    "# Recall result\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc904bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a metric object\n",
    "m = Precision()\n",
    "\n",
    "# Calculating the recall value\n",
    "m.update_state(y_true, y_hat)\n",
    "\n",
    "# Recall result\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a29de00",
   "metadata": {},
   "source": [
    "## 4. Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414c991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plot size\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "# Set first subplot\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(test_input[2])\n",
    "\n",
    "# Set second subplot\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(test_val[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6487df2",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0211dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights\n",
    "siamese_model.save('siamesemodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad132cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload model\n",
    "model = tf.keras.models.load_model('siamesemodel.h5', \n",
    "                                   custom_objects={'L1Dist':L1Dist, 'BinaryCrossentropy':tf.losses.BinaryCrossentropy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c36b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with reloaded model\n",
    "model.predict([test_input, test_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda8bae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fc7fe0",
   "metadata": {},
   "source": [
    "# Real Time Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7464d5",
   "metadata": {},
   "source": [
    "## 1. Verification Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c043e9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.listdir(os.path.join('application_data', 'verification_images'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2596ad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join('application_data', 'input_image', 'input_image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c7eddf",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for image in os.listdir(os.path.join('application_data', 'verification_images')):\n",
    "    validation_img = preprocess(os.path.join('application_data', 'verification_images', image))\n",
    "    print(validation_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d29a387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(model, detection_threshold, verification_threshold):\n",
    "    # Build results array\n",
    "    results = []\n",
    "    for image in os.listdir(os.path.join('application_data', 'verification_images')):\n",
    "        input_img = preprocess(os.path.join('application_data', 'input_image', 'input_image.jpg'))\n",
    "        validation_img = preprocess(os.path.join('application_data', 'verification_images', image))\n",
    "        \n",
    "        result = model.predict(list(np.expand_dims([input_img, validation_img], axis=1)))\n",
    "        results.append(result)\n",
    "    \n",
    "    # Dectection Threshold: Metric above which a prediction is considered positive\n",
    "    detection = np.sum(np.array(results) > detection_threshold)\n",
    "    \n",
    "    # Verification Threshold: Proportion of positive predictions / total positive samples\n",
    "    verification = detection / len(os.listdir(os.path.join('application_data', 'verification_images')))\n",
    "    verified = verification > verification_threshold\n",
    "    \n",
    "    return results, verified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237c27bf",
   "metadata": {},
   "source": [
    "## 2. OpenCV Real Time Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7d5e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    frame = frame[120:120+250, 200:200+250, :]\n",
    "    \n",
    "    cv2.imshow('verification', frame)\n",
    "    \n",
    "    # Verification trigger\n",
    "    if cv2.waitKey(10) & 0xFF == ord('v'):\n",
    "        # Save input image to application_data/input_image folder\n",
    "        cv2.imwrite(os.path.join('application_data', 'input_image', 'input_image.jpg'), frame)\n",
    "        # Run verification\n",
    "        results, verified = verify(model, 0.9, 0.7)\n",
    "        print(verified)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1765d971",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.squeeze(results) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0842c237",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.squeeze(results) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70f26fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfca708b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
